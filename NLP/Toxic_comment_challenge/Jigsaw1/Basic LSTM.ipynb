{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalAveragePooling1D,GlobalMaxPool1D\n",
    "# Difference between various GlobalAveragePooling, GlobalMaxPool\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "import sys\n",
    "# sys.setrecursionlimit(100000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[prediction_classes]\n",
    "\n",
    "train_sentences = train.comment_text\n",
    "test_sentences = test.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer to split, preprocess, encode input text data\n",
    "\n",
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words = max_features)\n",
    "tokenizer.fit_on_texts(list(train_sentences))\n",
    "# list_tokenizer_train = tokenizer.texts_to_sequences(train_sentences)\n",
    "list_tokenizer_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "# len_distribution = [len(arr) for arr in list_tokenizer_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences to a fixed length input.\n",
    "maxlen = 200\n",
    "# X_train = pad_sequences(list_tokenizer_train, maxlen = maxlen)\n",
    "X_test = pad_sequences(list_tokenizer_test, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "\n",
    "# Define input layer\n",
    "inp = Input(shape=(200, ))\n",
    "\n",
    "# Define embedding layer\n",
    "embed_size = 128\n",
    "x = Embedding(input_dim = max_features, output_dim=embed_size)(inp)\n",
    "x = LSTM(60, return_sequences=True, name = 'lstm_layer1')(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation = 'relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation = 'sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation and compilation\n",
    "model = Model(inputs = inp, outputs = x)\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model for 10 epochs \n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "model.fit(X_train, y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('keras_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model loaded\n",
      "Predictions calculated\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_filename):\n",
    "    \n",
    "    model = load_model(model_filename)\n",
    "    return model\n",
    "      \n",
    "\n",
    "print('Trained model loaded')\n",
    "output = model.predict(X_test)\n",
    "print('Predictions calculated')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions to csv file\n",
      "File written and ready to be uploaded\n"
     ]
    }
   ],
   "source": [
    "def make_submission_csv(output, prediction_classes):\n",
    "    output_df = pd.DataFrame(output, columns = prediction_classes)\n",
    "    output_df_upload = test.join(output_df)\n",
    "    output_df_upload = output_df_upload[['id'] + prediction_classes]\n",
    "    print('Writing predictions to csv file')\n",
    "    output_df_upload.to_csv('submission.csv', index = False)\n",
    "    print('File written and ready to be uploaded')\n",
    "\n",
    "make_submission_csv(output, prediction_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.96652067e-01, 3.80871773e-01, 9.70974624e-01, 5.59741519e-02,\n",
       "        8.96210015e-01, 2.01338068e-01],\n",
       "       [1.09159970e-03, 6.76032232e-06, 1.29854627e-04, 5.41037698e-05,\n",
       "        1.92135878e-04, 7.55947985e-05],\n",
       "       [2.13384815e-03, 1.40314369e-05, 2.15546432e-04, 1.02011996e-04,\n",
       "        3.83184932e-04, 1.43021694e-04],\n",
       "       [7.11207977e-04, 1.40598831e-06, 8.71279844e-05, 1.38668702e-05,\n",
       "        9.54512288e-05, 4.05575847e-05],\n",
       "       [4.29602107e-03, 4.61237869e-05, 4.51119646e-04, 2.94028636e-04,\n",
       "        8.17678403e-04, 3.34060343e-04]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
